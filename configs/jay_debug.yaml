# Tokenizer
# These paths are used to save the tokenizer and vocab. Name accordingly.
tokenizer_path: C:\Users\jayor\Documents\repos\Rocket-Launch\Rocket-Launch\dataset\tokenizers\tokenizer.model
vocab_path: C:\Users\jayor\Documents\repos\Rocket-Launch\Rocket-Launch\dataset\tokenizers\tokenizer.vocab
pad_id: -1 # defined later by tokenizer. NOTE: padding is disabled by default, see tokenizer.py
vocab_size: -1  # defined later by tokenizer

# Paths
# default_root_dir is the root model training directory; checkpoints, predictions, and logs will be saved here.
default_root_dir: C:\Users\jayor\Documents\repos\Rocket-Launch\Rocket-Launch\runs\1-25-debug
# which checkpoint to use, if any, for resuming training or inference
checkpoint_path: ~

# Dataset
# Name of hf hub dataset repo, if being used. Leave blank if not : ~
hf_dataset_name: wikitext
hf_dataset_config: wikitext-2-v1
dataset_directory: C:\Users\jayor\Documents\repos\Rocket-Launch\Rocket-Launch\dataset\raw\wikitext

# Raw data file. Tokenizer expects parquet, could be changed.
raw_dataset_path: ~

# Alternatively, raw paths for train/test/val if they came split
raw_train_path: C:\Users\jayor\Documents\repos\Rocket-Launch\Rocket-Launch\dataset\raw\wikitext\train.csv
raw_test_path: C:\Users\jayor\Documents\repos\Rocket-Launch\Rocket-Launch\dataset\raw\wikitext\test.csv
raw_val_path: C:\Users\jayor\Documents\repos\Rocket-Launch\Rocket-Launch\dataset\raw\wikitext\validation.csv

# Full tokenized data file, not necessary. Must be .pkl file
tokenized_dataset_path: ~

# Dataset split, must be .pkl file
train_path: C:\Users\jayor\Documents\repos\Rocket-Launch\Rocket-Launch\dataset\tokenized\train.pkl
val_path: C:\Users\jayor\Documents\repos\Rocket-Launch\Rocket-Launch\dataset\tokenized\eval.pkl
test_path: C:\Users\jayor\Documents\repos\Rocket-Launch\Rocket-Launch\dataset\tokenized\test.pkl

# GPU
use_slurm: false
accelerator: gpu
num_nodes: 1
devices: 1

# Train
gradient_accumulation_steps: 1
num_epochs: 5
lr: 3.0e-4 
gamma: 0.85
seed: 42
early_stopping: 5
save_top_k: 1
save_predictions_during_training: true
val_check_interval: 0.2
log_every_n_steps: 200
check_val_every_n_epoch: 1

# Inference
inference_path: C:\Users\jayor\Documents\repos\Rocket-Launch\Rocket-Launch\dataset\raw\inference_text.txt
max_gen_len: 20

# Model
from_pretrained: false
model_name: ~ # * Pretrained model name, if using pretrained model
dim: 128
n_layers: 4
n_heads: 4
multiple_of: 256  # make SwiGLU hidden layer size multiple of large power of 2
norm_eps: 1.0e-5
batch_size: 1
max_sequence_embeddings: 256
dim_k: ~
dim_v: ~
